{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "This notebook looks at the problems posed in the Numer.AI financial prediction tournament.  Its objective is to better understand the application of ML to extremely noises problems found in the areas of financial markets and economics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/numerai_training_data.csv')\n",
    "test = pd.read_csv('data/numerai_tournament_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial validation selection\n",
    "Ensure that the training data is representative of the test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['is_test'] = 0\n",
    "test['is_test'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264877,)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['t_id'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.concat(( train, test ))\n",
    "\n",
    "data = data.iloc[ np.random.permutation(len( data )) ]\n",
    "data.reset_index( drop = True, inplace = True )\n",
    "\n",
    "x_to_select = data.drop( ['target', 'is_test', 't_id' ], axis = 1 )\n",
    "y_to_select = data['is_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict if representative of test set\n",
    "Use a random forest to choose which data should be included for training.  This helps to mitigate noise data or data that is irrelevant to the prediction problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model_select = RandomForestClassifier(n_estimators=10).fit(x_to_select, y_to_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_adv = train.drop(['target','is_test'], axis=1)\n",
    "y_adv = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = rf_model_select.predict_proba(x_adv) > 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selected = (train[pred > 0]).drop('is_test', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selected.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier for target prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_selected_bin = pd.get_dummies(selected['target']).values\n",
    "y_selected = selected['target'].values\n",
    "x_selected = selected.drop('target', axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_selected, y_selected, test_size=.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=900, max_depth=6).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = rf_model.predict(x_valid)\n",
    "y_prob = rf_model.predict_proba(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.513614838109\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print(roc_auc_score(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.600139643751\n",
      "0.396400255301\n"
     ]
    }
   ],
   "source": [
    "print(np.max(y_prob[:,1]))\n",
    "print(np.min(y_prob[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_sub = rf_model.predict_proba(test.drop(['t_id','is_test'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.590737464136\n",
      "0.420029060885\n"
     ]
    }
   ],
   "source": [
    "print(np.max(y_sub[:,1]))\n",
    "print(np.min(y_sub[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({ 't_id':test['t_id'], 'probability':y_sub[:,1] })\n",
    "submit.to_csv('sub_5_rf.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Classifier for target prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(probability=True).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = svm_model.predict(x_valid)\n",
    "y_prob = svm_model.predict_proba(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.509301929298\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-177-67d4be7fa3fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_sub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m't_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'is_test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/nic/apps/python_data_analytics/2.7.12/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36m_predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    623\u001b[0m         pred_proba = (self._sparse_predict_proba\n\u001b[1;32m    624\u001b[0m                       if self._sparse else self._dense_predict_proba)\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpred_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/nic/apps/python_data_analytics/2.7.12/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36m_dense_predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobA_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobB_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             \u001b[0msvm_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msvm_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m             cache_size=self.cache_size, coef0=self.coef0, gamma=self._gamma)\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpprob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "y_sub = svm_model.predict_proba(test.drop(['t_id','is_test'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(np.max(y_sub[:,1]))\n",
    "print(np.min(y_sub[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({ 't_id':test['t_id'], 'probability':y_sub[:,1] })\n",
    "submit.to_csv('sub_2_svm.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Classifier for target prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7967, 50)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(x_selected, y_selected_bin, test_size=.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(512, input_dim=(x_train.shape[1]), init='normal'))\n",
    "\n",
    "for i in range(1,8):\n",
    "    model.add(Dense(512, init='normal'))\n",
    "    model.add(Dropout(.4))\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metric='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6373 samples, validate on 1594 samples\n",
      "Epoch 1/500\n",
      "1s - loss: 2.2064 - val_loss: 0.6986\n",
      "Epoch 2/500\n",
      "1s - loss: 1.3040 - val_loss: 0.7172\n",
      "Epoch 3/500\n",
      "1s - loss: 1.0662 - val_loss: 0.8007\n",
      "Epoch 4/500\n",
      "0s - loss: 0.9448 - val_loss: 0.7488\n",
      "Epoch 5/500\n",
      "0s - loss: 0.8995 - val_loss: 0.7176\n",
      "Epoch 6/500\n",
      "1s - loss: 0.8477 - val_loss: 0.7162\n",
      "Epoch 7/500\n",
      "1s - loss: 0.8237 - val_loss: 0.6994\n",
      "Epoch 8/500\n",
      "1s - loss: 0.8148 - val_loss: 0.6947\n",
      "Epoch 9/500\n",
      "1s - loss: 0.7780 - val_loss: 0.6963\n",
      "Epoch 10/500\n",
      "1s - loss: 0.7850 - val_loss: 0.6937\n",
      "Epoch 11/500\n",
      "1s - loss: 0.7763 - val_loss: 0.6938\n",
      "Epoch 12/500\n",
      "1s - loss: 0.7574 - val_loss: 0.6943\n",
      "Epoch 13/500\n",
      "0s - loss: 0.7487 - val_loss: 0.6949\n",
      "Epoch 14/500\n",
      "1s - loss: 0.7633 - val_loss: 0.6944\n",
      "Epoch 15/500\n",
      "0s - loss: 0.7559 - val_loss: 0.6941\n",
      "Epoch 16/500\n",
      "1s - loss: 0.7466 - val_loss: 0.6942\n",
      "Epoch 17/500\n",
      "1s - loss: 0.7490 - val_loss: 0.6949\n",
      "Epoch 18/500\n",
      "1s - loss: 0.7487 - val_loss: 0.6934\n",
      "Epoch 19/500\n",
      "0s - loss: 0.7480 - val_loss: 0.6952\n",
      "Epoch 20/500\n",
      "1s - loss: 0.7414 - val_loss: 0.6954\n",
      "Epoch 21/500\n",
      "0s - loss: 0.7494 - val_loss: 0.6960\n",
      "Epoch 22/500\n",
      "1s - loss: 0.7435 - val_loss: 0.6952\n",
      "Epoch 23/500\n",
      "1s - loss: 0.7442 - val_loss: 0.6945\n",
      "Epoch 24/500\n",
      "1s - loss: 0.7355 - val_loss: 0.6968\n",
      "Epoch 25/500\n",
      "1s - loss: 0.7344 - val_loss: 0.6944\n",
      "Epoch 26/500\n",
      "1s - loss: 0.7308 - val_loss: 0.6943\n",
      "Epoch 27/500\n",
      "1s - loss: 0.7330 - val_loss: 0.6950\n",
      "Epoch 28/500\n",
      "0s - loss: 0.7252 - val_loss: 0.6943\n",
      "Epoch 29/500\n",
      "1s - loss: 0.7237 - val_loss: 0.6953\n",
      "Epoch 30/500\n",
      "1s - loss: 0.7358 - val_loss: 0.6940\n",
      "Epoch 31/500\n",
      "0s - loss: 0.7238 - val_loss: 0.6945\n",
      "Epoch 32/500\n",
      "1s - loss: 0.7302 - val_loss: 0.6942\n",
      "Epoch 33/500\n",
      "1s - loss: 0.7253 - val_loss: 0.6943\n",
      "Epoch 34/500\n",
      "1s - loss: 0.7236 - val_loss: 0.6938\n",
      "Epoch 35/500\n",
      "1s - loss: 0.7215 - val_loss: 0.6945\n",
      "Epoch 36/500\n",
      "0s - loss: 0.7282 - val_loss: 0.6940\n",
      "Epoch 37/500\n",
      "0s - loss: 0.7249 - val_loss: 0.6940\n",
      "Epoch 38/500\n",
      "0s - loss: 0.7213 - val_loss: 0.6939\n",
      "Epoch 39/500\n",
      "1s - loss: 0.7175 - val_loss: 0.6940\n",
      "Epoch 40/500\n",
      "0s - loss: 0.7258 - val_loss: 0.6936\n",
      "Epoch 41/500\n",
      "1s - loss: 0.7270 - val_loss: 0.6940\n",
      "Epoch 42/500\n",
      "0s - loss: 0.7233 - val_loss: 0.6943\n",
      "Epoch 43/500\n",
      "1s - loss: 0.7141 - val_loss: 0.6943\n",
      "Epoch 44/500\n",
      "1s - loss: 0.7176 - val_loss: 0.6944\n",
      "Epoch 45/500\n",
      "1s - loss: 0.7113 - val_loss: 0.6944\n",
      "Epoch 46/500\n",
      "0s - loss: 0.7236 - val_loss: 0.6938\n",
      "Epoch 47/500\n",
      "0s - loss: 0.7111 - val_loss: 0.6937\n",
      "Epoch 48/500\n",
      "1s - loss: 0.7173 - val_loss: 0.6935\n",
      "Epoch 49/500\n",
      "1s - loss: 0.7091 - val_loss: 0.6934\n",
      "Epoch 50/500\n",
      "0s - loss: 0.7205 - val_loss: 0.6932\n",
      "Epoch 51/500\n",
      "1s - loss: 0.7168 - val_loss: 0.6942\n",
      "Epoch 52/500\n",
      "0s - loss: 0.7205 - val_loss: 0.6941\n",
      "Epoch 53/500\n",
      "0s - loss: 0.7157 - val_loss: 0.6947\n",
      "Epoch 54/500\n",
      "1s - loss: 0.7133 - val_loss: 0.6945\n",
      "Epoch 55/500\n",
      "1s - loss: 0.7100 - val_loss: 0.6939\n",
      "Epoch 56/500\n",
      "0s - loss: 0.7109 - val_loss: 0.6944\n",
      "Epoch 57/500\n",
      "0s - loss: 0.7141 - val_loss: 0.6943\n",
      "Epoch 58/500\n",
      "1s - loss: 0.7125 - val_loss: 0.6941\n",
      "Epoch 59/500\n",
      "1s - loss: 0.7156 - val_loss: 0.6938\n",
      "Epoch 60/500\n",
      "1s - loss: 0.7111 - val_loss: 0.6936\n",
      "Epoch 61/500\n",
      "1s - loss: 0.7149 - val_loss: 0.6937\n",
      "Epoch 62/500\n",
      "1s - loss: 0.7096 - val_loss: 0.6938\n",
      "Epoch 63/500\n",
      "1s - loss: 0.7081 - val_loss: 0.6938\n",
      "Epoch 64/500\n",
      "0s - loss: 0.7071 - val_loss: 0.6938\n",
      "Epoch 65/500\n",
      "1s - loss: 0.7109 - val_loss: 0.6944\n",
      "Epoch 66/500\n",
      "0s - loss: 0.7085 - val_loss: 0.6941\n",
      "Epoch 67/500\n",
      "1s - loss: 0.7135 - val_loss: 0.6944\n",
      "Epoch 68/500\n",
      "1s - loss: 0.7145 - val_loss: 0.6952\n",
      "Epoch 69/500\n",
      "1s - loss: 0.7122 - val_loss: 0.6945\n",
      "Epoch 70/500\n",
      "1s - loss: 0.7113 - val_loss: 0.6940\n",
      "Epoch 71/500\n",
      "1s - loss: 0.7033 - val_loss: 0.6942\n",
      "Epoch 72/500\n",
      "0s - loss: 0.7107 - val_loss: 0.6946\n",
      "Epoch 73/500\n",
      "1s - loss: 0.7082 - val_loss: 0.6954\n",
      "Epoch 74/500\n",
      "1s - loss: 0.7090 - val_loss: 0.6963\n",
      "Epoch 75/500\n",
      "0s - loss: 0.7090 - val_loss: 0.6948\n",
      "Epoch 76/500\n",
      "0s - loss: 0.7062 - val_loss: 0.6954\n",
      "Epoch 77/500\n",
      "1s - loss: 0.7095 - val_loss: 0.6941\n",
      "Epoch 78/500\n",
      "1s - loss: 0.7103 - val_loss: 0.6949\n",
      "Epoch 79/500\n",
      "1s - loss: 0.7099 - val_loss: 0.6948\n",
      "Epoch 80/500\n",
      "1s - loss: 0.7033 - val_loss: 0.6943\n",
      "Epoch 81/500\n",
      "1s - loss: 0.7064 - val_loss: 0.6947\n",
      "Epoch 82/500\n",
      "1s - loss: 0.7030 - val_loss: 0.6940\n",
      "Epoch 83/500\n",
      "1s - loss: 0.7068 - val_loss: 0.6943\n",
      "Epoch 84/500\n",
      "1s - loss: 0.7038 - val_loss: 0.6939\n",
      "Epoch 85/500\n",
      "0s - loss: 0.7056 - val_loss: 0.6939\n",
      "Epoch 86/500\n",
      "1s - loss: 0.6996 - val_loss: 0.6937\n",
      "Epoch 87/500\n",
      "1s - loss: 0.7045 - val_loss: 0.6939\n",
      "Epoch 88/500\n",
      "1s - loss: 0.7026 - val_loss: 0.6942\n",
      "Epoch 89/500\n",
      "1s - loss: 0.7017 - val_loss: 0.6944\n",
      "Epoch 90/500\n",
      "0s - loss: 0.7035 - val_loss: 0.6942\n",
      "Epoch 91/500\n",
      "0s - loss: 0.7034 - val_loss: 0.6939\n",
      "Epoch 92/500\n",
      "1s - loss: 0.7021 - val_loss: 0.6938\n",
      "Epoch 93/500\n",
      "1s - loss: 0.6994 - val_loss: 0.6939\n",
      "Epoch 94/500\n",
      "1s - loss: 0.7021 - val_loss: 0.6947\n",
      "Epoch 95/500\n",
      "0s - loss: 0.6992 - val_loss: 0.6944\n",
      "Epoch 96/500\n",
      "1s - loss: 0.7000 - val_loss: 0.6941\n",
      "Epoch 97/500\n",
      "1s - loss: 0.6977 - val_loss: 0.6948\n",
      "Epoch 98/500\n",
      "1s - loss: 0.6999 - val_loss: 0.6943\n",
      "Epoch 99/500\n",
      "1s - loss: 0.7014 - val_loss: 0.6942\n",
      "Epoch 100/500\n",
      "1s - loss: 0.7008 - val_loss: 0.6952\n",
      "Epoch 101/500\n",
      "1s - loss: 0.6997 - val_loss: 0.6950\n",
      "Epoch 102/500\n",
      "1s - loss: 0.6997 - val_loss: 0.6954\n",
      "Epoch 103/500\n",
      "0s - loss: 0.6986 - val_loss: 0.6957\n",
      "Epoch 104/500\n",
      "1s - loss: 0.7002 - val_loss: 0.6951\n",
      "Epoch 105/500\n",
      "1s - loss: 0.6987 - val_loss: 0.6939\n",
      "Epoch 106/500\n",
      "0s - loss: 0.6980 - val_loss: 0.6938\n",
      "Epoch 107/500\n",
      "0s - loss: 0.6969 - val_loss: 0.6938\n",
      "Epoch 108/500\n",
      "0s - loss: 0.7004 - val_loss: 0.6939\n",
      "Epoch 109/500\n",
      "1s - loss: 0.6997 - val_loss: 0.6941\n",
      "Epoch 110/500\n",
      "1s - loss: 0.7006 - val_loss: 0.6945\n",
      "Epoch 111/500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-149-5a3f354cc373>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/nic/apps/python_data_analytics/2.7.12/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/nic/apps/python_data_analytics/2.7.12/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/nic/apps/python_data_analytics/2.7.12/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m    841\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/nic/apps/python_data_analytics/2.7.12/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1601\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1602\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 1603\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   1604\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/nic/apps/python_data_analytics/2.7.12/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/nic/apps/python_data_analytics/2.7.12/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/nic/apps/python_data_analytics/2.7.12/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/nic/apps/python_data_analytics/2.7.12/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/nic/apps/python_data_analytics/2.7.12/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, nb_epoch=500, batch_size=2048, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.525915153729\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.555118\n",
      "0.413291\n"
     ]
    }
   ],
   "source": [
    "print(np.max(pred[:,1]))\n",
    "print(np.min(pred[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_sub = model.predict(test.drop(['t_id','is_test'], axis=1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({ 't_id':test['t_id'], 'probability':y_sub[:,1] })\n",
    "submit.to_csv('sub_1_nn.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
